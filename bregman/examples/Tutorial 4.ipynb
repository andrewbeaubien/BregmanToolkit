{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examples_soundspotter.py\n",
      "#\n",
      "# An example application using the bregman toolkit\n",
      "#\n",
      "# Match segments from a target audio file to segments from a source database\n",
      "# using overlapping sequences audio features (shingles)\n",
      "#\n",
      "# Based on the following publications:\n",
      "#\n",
      "# Casey, M. \"Soundspotter\", http://sourceforge.net/projects/mp7c/ (2003-)\n",
      "#\n",
      "# Casey, M. and Slaney, M. \"The Importance of Sequences for Music Similarity\", \n",
      "# Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), \n",
      "# Toulouse, France, May 2006\n",
      "#\n",
      "# Casey, M., \"Soundspotting: A New Kind of Process?\" \n",
      "# in R. Dean (Ed.), The Oxford Handbook of Computer Music and Digital Sound Culture, \n",
      "# Oxford University Press, 2009.\n",
      "#\n",
      "# Author: Michael A. Casey\n",
      "# Bregman Music and Auditory Research Studio, Dartmouth College\n",
      "\n",
      "from bregman.suite import *\n",
      "from bisect import bisect_right\n",
      "from numpy import concatenate, hstack, cumsum, array, zeros, exp, hamming, isnan\n",
      "from matplotlib.mlab import rms_flat\n",
      "\n",
      "default_params = default_feature_params()\n",
      "default_params['feature']='mfcc'\n",
      "default_params['ncoef']=20\n",
      "default_params['nhop']=2205\n",
      "\n",
      "def extract_target_feature_sequences(target_file, p=default_params, win=20, hop=10):\n",
      "    \"\"\" \n",
      "    inputs:\n",
      "     target_file - file name of target media (the one to reconstruct)\n",
      "     p - feature_params (see default_params)\n",
      "     win - stack features into length win sequences\n",
      "     hop - skip hop vectors per query\n",
      "    returns:\n",
      "     features X - feature matrix for target\n",
      "    \"\"\"\n",
      "    F = Features(target_file,p)\n",
      "    X = adb.stack_vectors(F.X.T, win, hop).T\n",
      "    return X\n",
      "\n",
      "def _feature_list_to_bounds(y_list):\n",
      "    # convert list of features to bounds array for mapping global match locations \n",
      "    # to per-media locators\n",
      "    bounds = [0]\n",
      "    for y in y_list:\n",
      "        bounds.append(y.shape[1])\n",
      "    return cumsum(array(bounds))\n",
      "\n",
      "def extract_source_feature_sequences(source_files, p=default_params, win=20, hop=10):\n",
      "    \"\"\"\n",
      "    inputs:\n",
      "     source_files - list of file names of source media (the database)\n",
      "     p - feature_params (see default_params)\n",
      "     win - stack features into length win sequences\n",
      "     hop - skip hop vectors per query\n",
      "    returns:\n",
      "     features Y - concatenated source feature matrices\n",
      "         bounds - list of cumulative lengths of matrices\n",
      "     \"\"\"\n",
      "    features = list()\n",
      "    for s in source_files:\n",
      "        F = Features(s,p)\n",
      "        features.append(adb.stack_vectors(F.X.T, win, hop).T)\n",
      "    return features\n",
      "\n",
      "def match_sequences(X, Y, num_hits=1):\n",
      "    \"\"\"\n",
      "    make a list of matches per target vector\n",
      "     inputs:\n",
      "      X - the target features (column-major)\n",
      "      Y - the list of source features (column-major)      \n",
      "      num_hits - how many matches to retrieve per query\n",
      "     returns:\n",
      "      matches - array of match positions, num_hits per input vector\n",
      "      distances - array of distances, num_hits per input vector\n",
      "    \"\"\"\n",
      "    D = euc_normed(X.T,hstack(Y).T)\n",
      "    DD = D.argsort(axis=1)[:,:num_hits]\n",
      "    D = array([D[k,DD[k,:]] for k in range(D.shape[0])])\n",
      "    return DD, D\n",
      "\n",
      "def _bounds_to_locator(m, bounds):\n",
      "    #return index of media corresponding to global match position in bounds\n",
      "    return bisect_right(bounds,m)-1\n",
      "\n",
      "def _bounds_to_index(m, bounds):\n",
      "    # return media locator corresponding to global match position in bounds\n",
      "    return m - bounds[_bounds_to_locator(m,bounds)]\n",
      "\n",
      "def _fetch_audio(f, i, p, w, h):\n",
      "    # retrieve audio segment from file\n",
      "    try:\n",
      "        x,sr,fmt = wavread(f, first=i*h*p['nhop'], last=w*p['nhop'])\n",
      "        x = x.sum(1) if len(x.shape)>1 else x\n",
      "    except RuntimeError: # not enough samples at end of file\n",
      "        x,sr,fmt = wavread(f, first=i*h*p['nhop'], last=None)\n",
      "        x = x.sum(1) if len(x.shape)>1 else x\n",
      "        x = concatenate([x,zeros(w*p['nhop']-len(x))]) # zero pad incomplete frame\n",
      "    return x\n",
      "\n",
      "def _sequence_overlap_add(y_list, p, win, hop):\n",
      "    # make new signal by overlapping and adding list of signals\n",
      "    y = zeros((len(y_list)*hop+win-1)*p['nhop'])\n",
      "    for i,k in enumerate(range(0, len(y_list)*hop*p['nhop'], hop*p['nhop'])):\n",
      "        end_k = min(len(y), k + win*p['nhop'])\n",
      "        y[k:end_k] += y_list[i][:end_k-k]\n",
      "    return y\n",
      "\n",
      "def reconstruct_audio(matches, distances, bounds, target_file, source_files, p, win, hop, beta=2.0):\n",
      "    \"\"\"\n",
      "    make a new audio signal based on matches and source media \n",
      "     inputs:\n",
      "      matches - list of matches from match_sequences\n",
      "      distances - list of distances from match_sequences\n",
      "      target_file - file name of target media (the one to reconstruct)      \n",
      "      source_files - list of file names of source media (the database)\n",
      "      p - feature parameters\n",
      "      win - sequence length\n",
      "      hop - sequence hop\n",
      "      beta - stiffness coefficient for mixing based on distances [2.0]\n",
      "     returns:\n",
      "      y - the reconstructued audio signal\n",
      "    \"\"\"\n",
      "    y_list = list()\n",
      "    hamm = hamming(p['nhop']*2)[:p['nhop']]\n",
      "    for i in range(len(matches)):\n",
      "        x = _fetch_audio(target_file, i, p, win, hop)\n",
      "        y = zeros((win*p['nhop']))\n",
      "        for j, m in enumerate(matches[i,:]):\n",
      "            yy = _fetch_audio(source_files[_bounds_to_locator(m,bounds)], _bounds_to_index(m,bounds), p, win, hop)\n",
      "            y +=  yy * exp(-beta * distances[i,j]) # weight match contribution by distance prior\n",
      "        y *= rms_flat(x) / rms_flat(y) # energy balance output rms using input rms\n",
      "        if win>1 and hop<win:\n",
      "            y[:p['nhop']]*=hamm\n",
      "            y[:-p['nhop']-1:-1]*=hamm\n",
      "        y_list.append(y) \n",
      "    return _sequence_overlap_add(y_list, p, win, hop)\n",
      "\n",
      "def soundspotter(target_file, source_files, p=default_params, win=20, hop=10, num_hits=1, beta=2.0, X=None, Y=None):\n",
      "    \"\"\"\n",
      "    A soundspotter\n",
      "     returns new audio based on target_file using source_files\n",
      "     inputs:\n",
      "       target - name of target media\n",
      "       sources - list of file names of source media\n",
      "       p - feature parameter dict [Features.defalt_params()]\n",
      "       win - sequence of vectors size for temporal context [20]\n",
      "       hop - number of vectors to advance per query [10]\n",
      "       num_hits - number of matches to find per query vector [1]\n",
      "       beta - stiffness coefficient for mixing based on distances [2.0]\n",
      "          X - pre-computed features for target\n",
      "          Y - list of pre-computed features for sources\n",
      "     outputs:\n",
      "       y - new audio signal\n",
      "    \"\"\"\n",
      "    X = X if X is not None else extract_target_feature_sequences(target_file, p, win, hop)\n",
      "    Y = Y if Y is not None else extract_source_feature_sequences(source_files, p, win, hop)\n",
      "    bounds = _feature_list_to_bounds(Y)\n",
      "    matches, distances = match_sequences(X,Y,num_hits)\n",
      "    y = reconstruct_audio(matches,distances,bounds,target_file,source_files,p,win,hop,beta)\n",
      "    y[isnan(y)]=0\n",
      "    return y    \n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print \"Running soundspotter on audio directory...\"\n",
      "    default_params['nhop']=882\n",
      "    default_params['lcoef']=3\n",
      "    sources = glob.glob(os.path.join(audio_dir,\"*.wav\"))\n",
      "    sources.sort()\n",
      "    y = soundspotter(os.path.join(audio_dir,\"amen.wav\"), sources[1:],\n",
      "                     p=default_params, win=5, hop=4, num_hits=5, beta=5.0)\n",
      "    play(balance_signal(y,'maxabs'))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running soundspotter on audio directory...\n",
        "Period size is"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64 , Buffer size is 22050\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}